{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7042d40d-baac-44ee-81e6-880bef3797bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing\n",
      "Import complete\n",
      "Loading Dataset...\n",
      "Training models...\n",
      "Model training complete.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your prompt (or 'exit' to quit):  children looking happily at starry night\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\georg\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "C:\\Users\\georg\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "C:\\Users\\georg\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:511: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "22220810\n",
      "0\n",
      "33330720\n",
      "0\n",
      "33330705\n",
      "0\n",
      "11110200\n",
      "0\n",
      "22220610\n",
      "0\n",
      "22220510\n",
      "Processed Classprompt: 0 0 0 0 0 0\n",
      "Processed Numprompt: 22220810 33330720 33330705 11110200 22220610 22220510\n",
      "Pre Checks\n",
      "Filter check allowed: 1\n",
      "running model...\n",
      "KNN Prediction for the custom prompt: 1\n",
      "Naive Bayes Prediction for the custom prompt: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 162\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     custom_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your prompt (or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m custom_prompt\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1286\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1287\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print('importing')\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    from datasets import load_dataset\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import time\n",
    "    import openai\n",
    "    import os\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    import re\n",
    "    from tqdm import tqdm\n",
    "    from collections import OrderedDict\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote = SMOTE()\n",
    "    print('Import complete')\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing module: {e}\")\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "import getpass\n",
    "if openai.api_key is None:\n",
    "    print(' ValueError(\"API key is missing. Please set the OPENAI_API_KEY environment variable.\")')\n",
    "    openai.api_key = getpass.getpass(\"Enter your API key: \")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai\n",
    "try:\n",
    "    print('Loading Dataset...')\n",
    "    prompts = pd.read_csv('df_subset.csv', \n",
    "    usecols=['Numbers', 'allowed'],\n",
    "    low_memory=False\n",
    ")\n",
    "    df=pd.read_csv('WordList.csv')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def classify_word(word):\n",
    "    # Define a system message and user prompt to classify each word\n",
    "    prompt = f\"Classify the word '{word}' into one of the following categories: 'illegal', 'explicit', 'violent', 'innocent'. Provide just the category as the output. Ensure one of these categories is no matter what stated.\"\n",
    "\n",
    "    # Call the OpenAI API with the prompt\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        \n",
    "        # Parse the response and extract the classification\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "        if 'illegal' in classification:\n",
    "            classification = 'illegal'\n",
    "        elif 'explicit' in classification:\n",
    "            classification = 'explicit'\n",
    "        elif 'violent' in classification:\n",
    "            classification = 'violent'\n",
    "        elif 'innocent' in classification:\n",
    "            classification = 'innocent'\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=30\n",
    "        )\n",
    "        # Map the response to a unique value\n",
    "        category_mapping = {\n",
    "            \"illegal\": 1,\n",
    "            \"explicit\": 2,\n",
    "            \"violent\": 3,\n",
    "            \"innocent\": 0\n",
    "        }\n",
    "        \n",
    "        # Return the mapped value\n",
    "        return category_mapping.get(classification, -1)  # Return -1 for unknown categories\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying word '{word}': {e}\")\n",
    "        return -1\n",
    "    \n",
    "def numberify(word):\n",
    "    # Define the user prompt\n",
    "    prompt = f\"HERE IS THE WORD: {word}\"\n",
    "\n",
    "    try:\n",
    "        # First classification: 4-digit number\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"Assign the word a number based on the following criteria.\n",
    "    The number will be 4 digits. The first 4 digits determine how 'bad' the word may be.\n",
    "    - Filler words = 1111\n",
    "    - Non-explicit subjects = 2222\n",
    "    - Non-explicit verbs = 3333\n",
    "    - Explicit words increase progressively (e.g., 5555, 6666, 7777, 8888)\n",
    "    - Use 9999 only for extreme cases.\n",
    "    Respond with just the number!.\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Second classification: 2-digit number based on implication\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"Assign the word a number from 00 to 99 based on severity.\n",
    "    - Use a balanced scale with 99 reserved for extreme words.\n",
    "    Respond with just the number!.\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        secondary = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Third classification: Letter count in 2-digit format\n",
    "        letter_count = len(re.findall(r'[a-zA-Z]', word))\n",
    "        formatted_count = str(letter_count).zfill(2)  # Ensures 2-digit format\n",
    "\n",
    "        # Combine all values into a single 8-digit number\n",
    "        final_number = int(f\"{classification}{formatted_count}{secondary}\")\n",
    "\n",
    "\n",
    "        return final_number, word  # Returns the combined number and word\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying word '{word}': {e}\")\n",
    "        return -1, word  # Returns -1 on error\n",
    "df['Word'] = df['Word'].str.lower()\n",
    "\n",
    "print(\"Training models...\")\n",
    "X = prompts['Numbers'].apply(lambda x: sum(x) if isinstance(x, list) else 0).values.reshape(-1, 1)  # If 'Numbers' is a list, sum them as a feature\n",
    "y = prompts['allowed']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "nb = GaussianNB(var_smoothing=1e-8)\n",
    "nb.fit(X_train_resampled, y_train_resampled)\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "while True:\n",
    "    custom_prompt = input(\"Enter your prompt (or 'exit' to quit): \")\n",
    "    if custom_prompt.lower() == 'exit':\n",
    "        break\n",
    "    elif custom_prompt.strip() == '':\n",
    "        print(\"Prompt cannot be empty.\")\n",
    "        continue\n",
    "    rows = []\n",
    "    Classprompt = custom_prompt.lower()\n",
    "    word_classifications = df.set_index('Word').to_dict()\n",
    "            # Clean up non-alphabetical characters (remove special characters)\n",
    "    Classprompt = re.sub(r'[^a-zA-Z\\s]', '', Classprompt)  \n",
    "    Numprompt = re.sub(r'[^a-zA-Z\\s]', '', Classprompt)  \n",
    "\n",
    "    numeric_values = []\n",
    "    classification_values = []\n",
    "\n",
    "    # Process words and classify them\n",
    "    for word in re.findall(r'\\b\\w+\\b', Classprompt):  # Loop through each word\n",
    "        word_row = df[df['Word'] == word]\n",
    "        if word_row.empty:\n",
    "            # Here, classify the word based on your own logic, e.g., classify_word, numberify\n",
    "            classification_value = classify_word(word)  # Classify word (you'll have to define this)\n",
    "            numeric_value, interpreted_word = numberify(word)  # Interpret numeric value (define this too)\n",
    "            new_row = pd.DataFrame({'Word': [word], 'Classification': [classification_value], \n",
    "                                    'Number': [numeric_value]})\n",
    "            df = pd.concat([df, new_row], ignore_index=True)\n",
    "            \n",
    "            # Use the newly classified values\n",
    "            current_classification = classification_value\n",
    "            current_numeric_value = numeric_value\n",
    "        else:\n",
    "            current_classification = word_row['Classification'].values[0]\n",
    "            current_numeric_value = word_row['Number'].values[0]\n",
    "            print(current_classification)\n",
    "            print(current_numeric_value)\n",
    "        Classprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(current_classification), Classprompt)\n",
    "        Numprompt = re.sub(r'\\b' + re.escape(word) + r'\\b', str(current_numeric_value), Numprompt)\n",
    "    \n",
    "    print(\"Processed Classprompt:\", Classprompt)\n",
    "    print(\"Processed Numprompt:\", Numprompt)\n",
    "    print(\"Pre Checks\")\n",
    "    Class_3_count = Classprompt.count('3')\n",
    "    Class_2_count = Classprompt.count('2')\n",
    "    Class_1_count = Classprompt.count('1')\n",
    "\n",
    "    Class_Sum_count = Class_3_count + Class_2_count + Class_1_count\n",
    "\n",
    "    # Apply filtering conditions\n",
    "    Guess_allowed = 1  # Default assumption (if conditions are not violated)\n",
    "    if Class_3_count > 4 or Class_2_count > 4 or Class_1_count > 4 or Class_Sum_count > 4:\n",
    "        Guess_allowed = 0\n",
    "\n",
    "    # Extract numbers from Numprompt\n",
    "    Numbers = list(map(int, re.findall(r'\\d+', Numprompt)))\n",
    "    Average_Number = sum(Numbers)/len(Numbers) if Numbers else 0\n",
    "\n",
    "    if Average_Number > 50000000:\n",
    "        Guess_allowed = 0\n",
    "    elif any(num > 60000000 for num in Numbers):\n",
    "        Guess_allowed = 0\n",
    "\n",
    "    # Print the result for the custom prompt\n",
    "    print(f\"Filter check allowed: {Guess_allowed}\")\n",
    "\n",
    "    print(\"running model...\")\n",
    "    def preprocess_custom_prompt(prompt):\n",
    "        # Extract numbers from the prompt\n",
    "        numbers = re.findall(r'\\d+', prompt)\n",
    "    \n",
    "        # Convert the numbers to integers\n",
    "        numbers = list(map(int, numbers))\n",
    "        \n",
    "        # Sum the numbers (or use alternative feature engineering)\n",
    "        sum_of_numbers = sum(numbers) if numbers else 0\n",
    "        \n",
    "        # Ensure non-zero variance and prevent extreme values\n",
    "        sum_of_numbers = max(1, min(sum_of_numbers, 1e8))\n",
    "        \n",
    "        # Reshape to match model input requirements\n",
    "        return np.array([[sum_of_numbers]])\n",
    "\n",
    "    X_custom = preprocess_custom_prompt(Numprompt)\n",
    "    custom_prediction = knn.predict(X_custom)\n",
    "    print(f\"KNN Prediction for the custom prompt: {custom_prediction[0]}\")\n",
    "    NBPredict = nb.predict(X_custom)\n",
    "    print(f\"Naive Bayes Prediction for the custom prompt: {NBPredict[0]}\")\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596338d3-1dea-490c-b82c-263bba5e56a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 867760 entries, 0 to 867759\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   image                     50000 non-null   object \n",
      " 1   prompt                    867578 non-null  object \n",
      " 2   seed                      50000 non-null   float64\n",
      " 3   step                      50000 non-null   float64\n",
      " 4   cfg                       50000 non-null   float64\n",
      " 5   sampler                   50000 non-null   object \n",
      " 6   width                     50000 non-null   float64\n",
      " 7   height                    50000 non-null   float64\n",
      " 8   user_name                 50000 non-null   object \n",
      " 9   timestamp                 50000 non-null   object \n",
      " 10  image_nsfw                867760 non-null  float64\n",
      " 11  prompt_nsfw               867760 non-null  float64\n",
      " 12  allowed                   867760 non-null  int64  \n",
      " 13  Classprompt               867213 non-null  object \n",
      " 14  Numprompt                 867213 non-null  object \n",
      " 15  Class 3 appearance count  867760 non-null  float64\n",
      " 16  Class 2 appearance count  867760 non-null  float64\n",
      " 17  Class 1 appearance count  867760 non-null  float64\n",
      " 18  Class Sum count           867760 non-null  float64\n",
      " 19  Guess allowed             867760 non-null  float64\n",
      " 20  Numbers                   867760 non-null  object \n",
      " 21  Average Number            867760 non-null  float64\n",
      " 22  Banned                    867760 non-null  int64  \n",
      "dtypes: float64(13), int64(2), object(8)\n",
      "memory usage: 152.3+ MB\n"
     ]
    }
   ],
   "source": [
    "prompts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f0a3dd-d428-43c9-b094-363a0b9d46cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc0ea5f-3327-44a7-9c1a-a02a99849bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image                        object\n",
      "prompt                       object\n",
      "seed                        float64\n",
      "step                        float64\n",
      "cfg                         float64\n",
      "sampler                      object\n",
      "width                       float64\n",
      "height                      float64\n",
      "user_name                    object\n",
      "timestamp                    object\n",
      "image_nsfw                  float64\n",
      "prompt_nsfw                 float64\n",
      "allowed                       int64\n",
      "Classprompt                  object\n",
      "Numprompt                    object\n",
      "Class 3 appearance count    float64\n",
      "Class 2 appearance count    float64\n",
      "Class 1 appearance count    float64\n",
      "Class Sum count             float64\n",
      "Guess allowed               float64\n",
      "Numbers                      object\n",
      "Average Number              float64\n",
      "Banned                        int64\n",
      "dtype: object\n",
      "image        object\n",
      "sampler      object\n",
      "user_name    object\n",
      "timestamp    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(prompts.dtypes)\n",
    "print(prompts.iloc[:, [0,5,8,9]].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cdedff-6ca8-477d-b9a9-7aaf457b2fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
