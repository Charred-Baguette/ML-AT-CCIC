{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce2e76e-8fd2-4a14-95be-2a7bc05fa009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f446bcc5-7b3e-4072-87bd-8ec6df59fe1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d078e7-7903-45d3-a0ab-d56275bb4796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb2016b8df44ec3a9c56d04f184d2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "part-000008.zip:   6%|5         | 31.5M/530M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3314b2fdf6a844a889c4c4683d5d9c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "part-000009.zip:   0%|          | 0.00/519M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a07e73f475e4a368ab249cb2ee26d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "part-000010.zip:   0%|          | 0.00/459M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataset = load_dataset('poloclub/diffusiondb', 'large_first_50k', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605792fe-7fe2-40f4-b427-12bf2bb21dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8b529-3491-4b2e-9d2a-b630230bdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df['train'].apply(pd.Series)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a506e07-be42-421d-945e-4b138f32f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = df.loc[0, 'image']\n",
    "image.show()\n",
    "image_array = np.array(image)\n",
    "print(image_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7218e-ec27-4a32-9e4f-a31bd5f79ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_rgb = image.convert('RGB')\n",
    "image_array = np.expand_dims(image_rgb, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c02a2-76e2-4936-86a2-e8f2563657b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d7697-c0f3-49d1-a7f1-a44032002f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if openai.api_key is None:\n",
    "    print(' ValueError(\"API key is missing. Please set the OPENAI_API_KEY environment variable.\")')\n",
    "    openai.api_key=input(\"whats your API key?\")\n",
    "# Initialize the OpenAI client\n",
    "client = openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3c594-7bf5-46a3-b918-656148635dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_word(word):\n",
    "    # Define a system message and user prompt to classify each word\n",
    "    prompt = f\"Classify the word '{word}' into one of the following categories: 'illegal', 'explicit', 'violent', 'innocent'. Provide just the category as the output.\"\n",
    "\n",
    "    # Call the OpenAI API with the prompt\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        \n",
    "        # Parse the response and extract the classification\n",
    "        classification = response.choices[0].message.content.strip()\n",
    "        if 'illegal' in classification:\n",
    "            classification = 'illegal'\n",
    "        elif 'explicit' in classification:\n",
    "            classification = 'explicit'\n",
    "        elif 'violent' in classification:\n",
    "            classification = 'violent'\n",
    "        elif 'innocent' in classification:\n",
    "            classification = 'innocent'\n",
    "        # Map the response to a unique value\n",
    "        category_mapping = {\n",
    "            \"illegal\": 1,\n",
    "            \"explicit\": 2,\n",
    "            \"violent\": 3,\n",
    "            \"innocent\": 0\n",
    "        }\n",
    "        \n",
    "        # Return the mapped value\n",
    "        return category_mapping.get(classification, -1)  # Return -1 for unknown categories\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying word '{word}': {e}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db226c5a-6e31-45cc-ae96-5fb9c364a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberify(word):\n",
    "    # Define a system message and user prompt to classify each word\n",
    "    prompt = f\"\"\"Assign the word a number based on the following criteria. The number will be 8 digits. the first 4 are to determine how much censorship the word may be. \n",
    "    Ensure a pattern is involved. Filler words will be 1111xxxx. Subjects(non explicit) will be 2222xxxx. Verbs (non explicit) will be 3333xxxx. Then have forward scaling for explicit words. \n",
    "    For example the word 'sex' will be 8888xxxx and the word 'rape' will be 9999xxxx. Have intermediate words follow a similar scale. \n",
    "    The final four numbers will be determined with the following. The first 2 numbers of the final 4 numbers will be based on word length. The following 2 numbers will be a fine scale of possible explicit value. \n",
    "    For example, the word sex will be classified as 88880395. If a word could have potential implications to violence, illegality, drugs, or explicit content, then give it a higher number than 400000. Use a good scale though. words like assassin or shot shouldnt be classified as 9999xxxx. Try to keep a balance with 5555xxxx, 6666xxxx, 7777xxxx, 8888xxxx.\n",
    "    Respond with just the number! HERE IS THE WORD: {word}\"\"\"\n",
    "\n",
    "    # Call the OpenAI API with the prompt\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that classifies words.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=10\n",
    "        )\n",
    "        \n",
    "        # Parse the response and extract the classification\n",
    "        classification = response.choices[0].message.content.strip()        \n",
    "        worded = word\n",
    "        return classification, worded\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying word '{word}': {e}\")\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6071a-b7e1-470a-a91b-1bbec24fcb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ba4c8-f545-45cb-99bf-7bfb9b5751f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Example DataFrame (replace this with your actual DataFrame)\n",
    "\n",
    "word_classifications = {}\n",
    "rows = []\n",
    "words_set = set()\n",
    "# Loop through the DataFrame and classify words across all rows\n",
    "for idx, row in df.iterrows():\n",
    "    prompt = row['prompt']\n",
    "    for word in re.findall(r'\\b\\w+\\b', prompt):  # Split the prompt into individual words\n",
    "        if word not in words_set:  # Avoid classifying the same word twice\n",
    "            words_set.add(word)\n",
    "            word_classifications[word] = {}\n",
    "            classification_value = classify_word(word)\n",
    "            numeric_value, interpreted_word=numberify(word)\n",
    "            rows.append([word, classification_value, numeric_value, interpreted_word])\n",
    "            print(word, classification_value, numeric_value, interpreted_word)\n",
    "        # Sleep to avoid hitting API rate limits\n",
    "        time.sleep(.5)  # Adjust the sleep time as necessary\n",
    "\n",
    "# Convert the dictionary to a DataFrame for better visualization\n",
    "word_classification_df = pd.DataFrame(rows, columns=[\"Word\", \"Classification\", \"Number\", \"NumericInterpretedWord\"])\n",
    "# Display the final DataFrame with words and their classifications\n",
    "print(word_classification_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27628aed-241a-4f2c-b1a7-3baf7970934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 1]\n"
     ]
    }
   ],
   "source": [
    "print(word_classification_df['Classification'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe2dd0-e935-4ac4-a11d-25d9be516d08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73b51f-bb50-41e4-9f52-de91a502df36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
